# Deepfake Detection Using Vision Transformer

## Overview
This project focuses on detecting deepfake images using Vision Transformer (ViT). Deepfake technology has significantly improved, making it increasingly difficult to differentiate between real and synthetic images. This project aims to develop a robust model capable of distinguishing deepfake images from authentic ones with high accuracy.

## Methodology
- **Dataset**: The model is trained on a dataset consisting of both real and deepfake images to ensure effective learning.
- **Preprocessing**: Images are resized and normalized before being fed into the Vision Transformer.
- **Model**: We use a pretrained Vision Transformer (ViT) model fine-tuned for deepfake detection.
- **Training**: The model is trained using transfer learning with cross-entropy loss for classification.
- **Evaluation**: The trained model is evaluated based on accuracy, precision, recall, and F1-score.

## Installation
1. Clone the repository:
   ```sh
   https://github.com/Saravana-2816/DF-WildCup.git
   ```


## Future Improvements
- Enhancing model robustness with additional datasets
- Optimizing model efficiency for real-time detection

